#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìˆ˜íŒŒë² ì´ìŠ¤ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì„œë¹„ìŠ¤
"""
import asyncio
import logging
from datetime import datetime, timedelta
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger
from app.services.supabase_schedule_service import supabase_schedule_service
from app.services.reddit_service import RedditService
from app.services.llm_service import LLMService
from app.services.supabase_reports_service import supabase_reports_service
from app.services.verified_analysis_service import VerifiedAnalysisService
import uuid
from typing import Optional

logger = logging.getLogger(__name__)

class SupabaseSchedulerService:
    def __init__(self):
        self.scheduler = AsyncIOScheduler(timezone="UTC")
        self.reddit_service = RedditService()
        self.llm_service = LLMService()
        self.verified_analysis_service = VerifiedAnalysisService()
        # ë©”ëª¨ë¦¬ ê¸°ë°˜ ì‹¤í–‰ ì¶”ì  (ì„œë²„ ì¬ì‹œì‘ ì‹œ ì´ˆê¸°í™”ë¨)
        self._executing_schedules = set()
        self._is_running = False
        
    def get_executing_schedules(self):
        """í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ìŠ¤ì¼€ì¤„ ID ëª©ë¡ ë°˜í™˜ (int íƒ€ì…ìœ¼ë¡œ ë³´ì¥)"""
        return list(self._executing_schedules)
        
    async def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if self._is_running:
            logger.warning("Scheduler is already running")
            return
            
        # ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë“  is_executing í”Œë˜ê·¸ ì´ˆê¸°í™”
        await self._reset_all_executing_flags()
        
        # 1ë¶„ë§ˆë‹¤ ì‹¤í–‰ë˜ëŠ” job ì¶”ê°€
        self.scheduler.add_job(
            self._check_and_execute_schedules,
            IntervalTrigger(minutes=1),
            id="check_schedules",
            name="Check and execute schedules",
            replace_existing=True
        )
        
        self.scheduler.start()
        self._is_running = True
        logger.info("ğŸš€ ìŠ¤ì¼€ì¤„ëŸ¬ ì„œë¹„ìŠ¤ ì‹œì‘ | ì²´í¬ ì£¼ê¸°: 1ë¶„")
        
    async def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        if self._is_running:
            self.scheduler.shutdown(wait=False)
            self._is_running = False
            # ì¤‘ì§€ ì‹œ ëª¨ë“  is_executing í”Œë˜ê·¸ ì´ˆê¸°í™”
            await self._reset_all_executing_flags()
            logger.info("Supabase Scheduler service stopped")
            
    async def _reset_all_executing_flags(self):
        """ëª¨ë“  ìŠ¤ì¼€ì¤„ì˜ is_executing í”Œë˜ê·¸ë¥¼ falseë¡œ ì´ˆê¸°í™”"""
        try:
            result = await supabase_schedule_service.reset_all_executing_flags()
            if result["success"]:
                logger.info(f"ğŸ”„ ì‹¤í–‰ í”Œë˜ê·¸ ì´ˆê¸°í™” ì™„ë£Œ | ë¦¬ì…‹ëœ ìŠ¤ì¼€ì¤„: {result['reset_count']}ê°œ")
            else:
                logger.error(f"Failed to reset executing flags: {result['message']}")
        except Exception as e:
            logger.error(f"Error resetting executing flags: {e}")
            
    async def _check_and_execute_schedules(self):
        """ì‹¤í–‰í•´ì•¼ í•  ìŠ¤ì¼€ì¤„ í™•ì¸ ë° ì‹¤í–‰"""
        current_time = datetime.utcnow()
        # í•œêµ­ ì‹œê°„ìœ¼ë¡œ í‘œì‹œ
        import pytz
        kst = pytz.timezone('Asia/Seoul')
        current_kst = current_time.replace(tzinfo=pytz.UTC).astimezone(kst)
        logger.debug(f"â° ìŠ¤ì¼€ì¤„ ì²´í¬ ì‹œì‘ | ì‹œê°„: {current_kst.strftime('%H:%M:%S')} KST (UTC: {current_time.strftime('%H:%M:%S')})")
        if self.get_executing_schedules():
            logger.debug(f"   í˜„ì¬ ì‹¤í–‰ ì¤‘: {self.get_executing_schedules()}")
        
        try:
            # ì‹¤í–‰ ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ì¼€ì¤„ ì¡°íšŒ (is_executing=Falseì¸ ê²ƒë§Œ)
            schedules = await supabase_schedule_service.get_schedules_to_execute()
            
            if schedules:
                logger.info(f"ğŸ“‹ ê²€ì‚¬í•  ìŠ¤ì¼€ì¤„: {len(schedules)}ê°œ")
                
                for schedule in schedules:
                    schedule_id = int(schedule["id"])
                    
                    # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ ë©”ëª¨ë¦¬ì—ì„œë„ í™•ì¸
                    if schedule_id in self._executing_schedules:
                        logger.debug(f"âš ï¸ ìŠ¤ì¼€ì¤„ {schedule_id} ì´ë¯¸ ì‹¤í–‰ ì¤‘ (ë©”ëª¨ë¦¬ ì²´í¬)")
                        continue
                    
                    # ì‹¤í–‰ ì‹œê°„ì´ ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    next_run = datetime.fromisoformat(schedule["next_run"].replace("Z", ""))
                    if next_run <= current_time:
                        # DB ë ˆë²¨ì—ì„œ ì›ìì ìœ¼ë¡œ ë½ íšë“ ì‹œë„
                        lock_acquired = await supabase_schedule_service.try_acquire_schedule_lock(schedule_id)
                        
                        if lock_acquired:
                            logger.info(f"ğŸ”’ ìŠ¤ì¼€ì¤„ {schedule_id} ë½ íšë“ ì„±ê³µ | í‚¤ì›Œë“œ: {schedule.get('keyword')}")
                            # ë©”ëª¨ë¦¬ì—ë„ ì¶”ê°€
                            self._executing_schedules.add(schedule_id)
                            # ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
                            asyncio.create_task(self._execute_schedule_with_lock(schedule))
                        else:
                            logger.debug(f"â³ ìŠ¤ì¼€ì¤„ {schedule_id} ë‹¤ë¥¸ ê³³ì—ì„œ ì‹¤í–‰ ì¤‘")
                    else:
                        # í•œêµ­ ì‹œê°„ìœ¼ë¡œ í‘œì‹œ
                        next_run_kst = next_run.replace(tzinfo=pytz.UTC).astimezone(kst)
                        logger.debug(f"â±ï¸ ìŠ¤ì¼€ì¤„ {schedule_id} ì•„ì§ ì‹¤í–‰ ì‹œê°„ ì•„ë‹˜ | ì˜ˆì •: {next_run_kst.strftime('%H:%M')} KST")
                        
        except Exception as e:
            logger.error(f"[SCHEDULER] Error checking schedules: {e}")
            
    async def _execute_schedule_with_lock(self, schedule):
        """ë½ì„ íšë“í•œ ìŠ¤ì¼€ì¤„ ì‹¤í–‰ (ë½ í•´ì œ ë³´ì¥)"""
        schedule_id = int(schedule["id"])
        
        try:
            await self._execute_schedule(schedule)
        finally:
            # í•­ìƒ ë½ í•´ì œ
            await supabase_schedule_service.release_schedule_lock(schedule_id)
            # ë©”ëª¨ë¦¬ì—ì„œë„ ì œê±°
            self._executing_schedules.discard(schedule_id)
            logger.info(f"ğŸ”“ ìŠ¤ì¼€ì¤„ {schedule_id} ë½ í•´ì œ ì™„ë£Œ")
            
    async def _execute_schedule(self, schedule):
        """ìŠ¤ì¼€ì¤„ ì‹¤í–‰"""
        max_retries = 3
        retry_count = 0
        execution_successful = False
        
        while retry_count < max_retries and not execution_successful:
            try:
                schedule_id = int(schedule["id"])
                logger.info(f"ğŸš€ ìŠ¤ì¼€ì¤„ ì‹¤í–‰ ì‹œì‘ | ID: {schedule_id} | ì‹œë„: {retry_count + 1}/{max_retries}")
                
                # ì§„í–‰ ìƒíƒœ ì„¸ì…˜ ID ìƒì„±
                session_id = f"schedule_{schedule_id}_{uuid.uuid4().hex[:8]}"
                
                # 1. Reddit ë°ì´í„° ìˆ˜ì§‘
                logger.info(f"ğŸ” Reddit ë°ì´í„° ìˆ˜ì§‘ ì¤‘ | í‚¤ì›Œë“œ: '{schedule['keyword']}'")
                posts = await self.reddit_service.collect_reddit_posts(schedule["keyword"])
                
                if not posts:
                    logger.warning(f"[SCHEDULER] No posts found for schedule {schedule_id}")
                    # ë°ì´í„°ê°€ ì—†ì–´ë„ ì‹¤í–‰ì€ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                    execution_successful = True
                    break
                
                logger.info(f"   ìˆ˜ì§‘ ì™„ë£Œ: {len(posts)}ê°œ ê²Œì‹œë¬¼")
                
                # 2. ë³´ê³ ì„œ ìƒì„±
                logger.info(f"ğŸ“ AI ë³´ê³ ì„œ ìƒì„± ì¤‘...")
                report_result = await self.verified_analysis_service.generate_verified_report(
                    query=schedule["keyword"],
                    posts=posts,
                    report_length=schedule.get("report_length", "moderate"),
                    session_id=session_id
                )
                
                # 3. ë³´ê³ ì„œ ì €ì¥
                report_data = {
                    "query_text": schedule["keyword"],  # search_query ëŒ€ì‹  query_text ì‚¬ìš©
                    "summary": report_result.get("summary", "ìš”ì•½ ì—†ìŒ"),
                    "full_report": report_result.get("full_report", "ë³´ê³ ì„œ ì—†ìŒ"),
                    "search_metadata": {
                        "sources": ["reddit"],
                        "posts_count": len(posts),
                        "schedule_id": schedule_id
                    },
                    "user_nickname": schedule.get("user_nickname"),
                    "session_id": session_id,
                    "posts_metadata": report_result.get("post_mappings", [])
                }
                
                save_result = await supabase_reports_service.save_report(report_data)
                
                if save_result["success"]:
                    logger.info(f"âœ… ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ | ìŠ¤ì¼€ì¤„ ID: {schedule_id}")
                    
                    # 4. ìŠ¤ì¼€ì¤„ ì—…ë°ì´íŠ¸ (ì„±ê³µ ì‹œì—ë§Œ)
                    # save_resultì—ì„œ report_id ê°€ì ¸ì˜¤ê¸° (report_id ë˜ëŠ” data.id)
                    report_id = save_result.get("report_id")
                    if not report_id and save_result.get("data"):
                        report_id = save_result["data"].get("id")
                    
                    if not report_id:
                        logger.error(f"âŒ ë³´ê³ ì„œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ | save_result: {save_result}")
                        raise Exception("Report ID not found in save result")
                    
                    update_result = await supabase_schedule_service.update_schedule_after_execution(
                        schedule_id=schedule_id,
                        interval_minutes=schedule.get("interval_minutes", 60),
                        report_id=report_id
                    )
                    
                    if update_result["success"]:
                        logger.info(f"âœ… ìŠ¤ì¼€ì¤„ ì—…ë°ì´íŠ¸ ì™„ë£Œ | ID: {schedule_id} | ë‹¤ìŒ ì‹¤í–‰: {schedule.get('interval_minutes')}ë¶„ í›„")
                        execution_successful = True
                        
                        # 5. ì•Œë¦¼ ìƒì„± (ì„ íƒì‚¬í•­)
                        if schedule.get("notification_enabled"):
                            await self._create_notification(schedule, report_id)
                    else:
                        logger.error(f"[SCHEDULER] Failed to update schedule: {update_result['message']}")
                        raise Exception(f"Schedule update failed: {update_result['message']}")
                else:
                    logger.error(f"[SCHEDULER] Failed to save report: {save_result['message']}")
                    raise Exception(f"Report save failed: {save_result['message']}")
                    
            except Exception as e:
                retry_count += 1
                logger.error(f"[SCHEDULER] Error executing schedule {schedule['id']} (attempt {retry_count}): {e}")
                
                if retry_count < max_retries:
                    logger.info(f"[SCHEDULER] Retrying in 5 seconds...")
                    await asyncio.sleep(5)
                else:
                    logger.error(f"[SCHEDULER] Max retries reached for schedule {schedule['id']}")
                    
                    # ìµœëŒ€ ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨í•˜ë©´ ìŠ¤ì¼€ì¤„ ìƒíƒœë¥¼ ì—ëŸ¬ë¡œ ë³€ê²½
                    if schedule.get("notification_enabled"):
                        await self._create_error_notification(schedule, str(e))
                        
        # ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ë§Œ ì—…ë°ì´íŠ¸ (completed_reportsëŠ” ì¦ê°€ì‹œí‚¤ì§€ ì•ŠìŒ)
        if not execution_successful:
            logger.error(f"[SCHEDULER] Schedule {schedule['id']} execution failed after all retries")
            # ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ì€ ì—…ë°ì´íŠ¸í•˜ì—¬ ë¬´í•œ ì¬ì‹œë„ ë°©ì§€
            await supabase_schedule_service.update_next_run_only(
                schedule_id=schedule["id"],
                interval_minutes=schedule.get("interval_minutes", 60)
            )
                        
    async def _create_notification(self, schedule, report_id):
        """ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ ì•Œë¦¼ ìƒì„±"""
        try:
            notification_data = {
                "user_nickname": schedule.get("user_nickname"),
                "title": "ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ",
                "message": f"'{schedule['keyword']}' í‚¤ì›Œë“œì— ëŒ€í•œ ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "type": "report_completed",
                "data": {
                    "schedule_id": schedule["id"],
                    "report_id": report_id,
                    "keyword": schedule["keyword"]
                }
            }
            
            result = await supabase_schedule_service.create_notification_async(notification_data)
            if result["success"]:
                logger.info(f"[SCHEDULER] Notification created for schedule {schedule['id']}")
            else:
                logger.error(f"[SCHEDULER] Failed to create notification: {result['message']}")
                
        except Exception as e:
            logger.error(f"[SCHEDULER] Error creating notification: {e}")
            
    async def _create_error_notification(self, schedule, error_message):
        """ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨ ì•Œë¦¼ ìƒì„±"""
        try:
            notification_data = {
                "user_nickname": schedule.get("user_nickname"),
                "title": "ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨",
                "message": f"'{schedule['keyword']}' í‚¤ì›Œë“œì— ëŒ€í•œ ë³´ê³ ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "type": "report_failed",
                "data": {
                    "schedule_id": schedule["id"],
                    "keyword": schedule["keyword"],
                    "error": error_message
                }
            }
            
            result = await supabase_schedule_service.create_notification_async(notification_data)
            if result["success"]:
                logger.info(f"[SCHEDULER] Error notification created for schedule {schedule['id']}")
                
        except Exception as e:
            logger.error(f"[SCHEDULER] Error creating error notification: {e}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
supabase_scheduler_service = SupabaseSchedulerService()