#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Reddit ë°ì´í„° ê²€ì¦ëœ ë¶„ì„ ë³´ê³ ì„œ - ê²€ì¦ ì—ì´ì „íŠ¸ í¬í•¨
"""
import json
import os
import sys
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
import time

# ìœˆë„ìš° í™˜ê²½ì—ì„œ ìœ ë‹ˆì½”ë“œ ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def validate_report_content(analysis_text):
    """ë³´ê³ ì„œ ë‚´ìš© ê²€ì¦ í•¨ìˆ˜"""
    
    # ê¸°ë³¸ ê²€ì¦ ì¡°ê±´ë“¤
    failure_indicators = [
        "ì£„ì†¡í•©ë‹ˆë‹¤",
        "ì‘ì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤", 
        "ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "ë¯¸ë˜ì˜ ì •ë³´",
        "ì‹¤ì‹œê°„ ì •ë³´ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "sorry",
        "cannot provide",
        "unable to",
        "I can't",
        "I cannot"
    ]
    
    # ìµœì†Œ ê¸¸ì´ ì²´í¬ (ë„ˆë¬´ ì§§ìœ¼ë©´ ì‹¤íŒ¨)
    if len(analysis_text) < 1000:
        return False, "ë³´ê³ ì„œê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤"
    
    # ì‹¤íŒ¨ ì§€ì‹œì–´ ì²´í¬
    for indicator in failure_indicators:
        if indicator.lower() in analysis_text.lower():
            return False, f"ê±°ë¶€ ì‘ë‹µ ê°ì§€: '{indicator}'"
    
    # í•„ìˆ˜ ì„¹ì…˜ ì²´í¬
    required_sections = ["í•µì‹¬", "ë‰´ìŠ¤", "ì •ë³´", "ë¶„ì„"]
    section_count = sum(1 for section in required_sections if section in analysis_text)
    if section_count < 2:
        return False, "í•„ìˆ˜ ì„¹ì…˜ì´ ë¶€ì¡±í•©ë‹ˆë‹¤"
    
    return True, "ê²€ì¦ í†µê³¼"

def generate_dynamic_title(topic, client):
    """GPT-4.1ë¡œ ë™ì  ì œëª© ìƒì„±"""
    try:
        title_prompt = f"""
ì£¼ì œ: "{topic}"

ì´ ì£¼ì œì— ëŒ€í•œ Reddit ë¶„ì„ ë³´ê³ ì„œì˜ ë§¤ë ¥ì ì´ê³  ì „ë¬¸ì ì¸ ì œëª©ì„ 1ê°œ ìƒì„±í•´ì£¼ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
1. í•œêµ­ì–´ë¡œ ì‘ì„±
2. 15-25ì ë‚´ì™¸
3. ë¶„ì„ ë³´ê³ ì„œì„ì„ ë‚˜íƒ€ë‚´ëŠ” ì œëª©
4. í¥ë¯¸ë¥¼ ë„ëŠ” í‚¤ì›Œë“œ í¬í•¨
5. í•œê¸€, ì˜ì–´, ìˆ«ì, ì–¸ë”ë°”(_), í•˜ì´í”ˆ(-), ê³µë°±ë§Œ ì‚¬ìš©
6. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ìëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ

ì˜ˆì‹œ: "ì• í”Œ ì£¼ê°€ ê¸‰ë“± ì‹ í˜¸ ë¶„ì„", "í…ŒìŠ¬ë¼ ì‹¤ì  ì¶©ê²© ë³´ê³ ì„œ", "íŠ¸ëŸ¼í”„-ë¨¸ìŠ¤í¬ ê°ˆë“± ë¶„ì„"

ì œëª©ë§Œ ì¶œë ¥í•˜ì„¸ìš”:
"""
        
        response = client.chat.completions.create(
            model="gpt-4.1",
            messages=[{"role": "user", "content": title_prompt}],
            temperature=0.8
        )
        
        dynamic_title = response.choices[0].message.content.strip()
        
        # ê°•ì œë¡œ ì´ëª¨ì§€ì™€ íŠ¹ìˆ˜ë¬¸ì ì œê±° (GPTê°€ ë¬´ì‹œí•  ê²½ìš° ëŒ€ë¹„)
        import re
        clean_title = re.sub(r'[^\w\sê°€-í£a-zA-Z0-9\-_]', '', dynamic_title)
        clean_title = re.sub(r'\s+', ' ', clean_title).strip()
        
        print(f"ğŸ¯ GPT-4.1 ì›ë³¸ ì œëª©: {dynamic_title}")
        if clean_title != dynamic_title:
            print(f"âš ï¸ ì´ëª¨ì§€/íŠ¹ìˆ˜ë¬¸ì ì œê±°ë¨: {clean_title}")
        
        return clean_title
        
    except Exception as e:
        print(f"âŒ ì œëª© ìƒì„± ì‹¤íŒ¨: {e}")
        return topic  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì£¼ì œ ì‚¬ìš©

def create_verified_detailed_analysis(search_topic=None):
    """ê²€ì¦ì´ í¬í•¨ëœ ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    
    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    # ìµœì‹  ê°€ì¤‘ì¹˜ ë°ì´í„° íŒŒì¼ ì°¾ê¸°
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(script_dir))
    raw_data_dir = os.path.join(project_root, "reports", "raw_data")
    
    data_files = [f for f in os.listdir(raw_data_dir) if f.startswith("weighted_search_") and f.endswith(".json")]
    
    if not data_files:
        print("âŒ ê°€ì¤‘ì¹˜ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ê°€ì¥ ìµœì‹  íŒŒì¼ ì„ íƒ (íŒŒì¼ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€)
    latest_file = sorted(data_files, key=lambda f: os.path.getmtime(os.path.join(raw_data_dir, f)))[-1]
    file_path = os.path.join(raw_data_dir, latest_file)
    
    print(f"ğŸ“‚ ë°ì´í„° íŒŒì¼ ë¡œë“œ: {latest_file}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    topic = data.get('topic', 'Unknown Topic')
    print(f"ğŸ“Š ë¶„ì„í•  ê²Œì‹œë¬¼: {data['total_posts']}ê°œ")
    print(f"ğŸ·ï¸  ì£¼ì œ: {topic}")
    
    # ë™ì  ì œëª© ìƒì„±
    dynamic_title = generate_dynamic_title(topic, client)
    
    # ëª¨ë“  ê²Œì‹œë¬¼ í†µí•© ë° ì •ë¦¬
    all_posts = []
    footnote_counter = 1
    all_footnotes = []
    
    for keyword, keyword_data in data['results_by_keyword'].items():
        for post in keyword_data['posts']:
            post['keyword'] = keyword
            all_posts.append(post)
    
    all_posts.sort(key=lambda x: x['created_utc'], reverse=True)
    
    # ì‹ ë¢°ë„ë³„ ë¶„ë¥˜
    verified_news = []
    rumors_speculation = []
    
    reliable_subreddits = ['worldnews', 'news', 'politics', 'technology', 'business']
    
    for post in all_posts:
        is_reliable = (
            post['score'] > 100 and 
            any(sub in post['subreddit'].lower() for sub in reliable_subreddits)
        )
        
        if is_reliable:
            verified_news.append(post)
        else:
            rumors_speculation.append(post)
    
    # ì½˜í…ì¸  ì¤€ë¹„
    news_content = []
    rumors_content = []
    
    # ë‰´ìŠ¤ ì½˜í…ì¸  (ìƒìœ„ 20ê°œ)
    for i, post in enumerate(verified_news[:20], 1):
        footnote_id = footnote_counter
        footnote_counter += 1
        
        post_time = datetime.fromtimestamp(post['created_utc'])
        time_diff = datetime.now() - post_time
        
        if time_diff.days > 0:
            time_str = f"{time_diff.days}ì¼ ì „"
        elif time_diff.seconds > 3600:
            time_str = f"{time_diff.seconds // 3600}ì‹œê°„ ì „"
        else:
            time_str = f"{time_diff.seconds // 60}ë¶„ ì „"
        
        post_content = f"""
ë‰´ìŠ¤ {i}. [{post['score']}ì ] {post['title']} [{footnote_id}]
- ê²Œì‹œ ì‹œê°„: {post_time.strftime('%Y-%m-%d %H:%M')} ({time_str})
- ì¶œì²˜: r/{post['subreddit']}
- ëŒ“ê¸€: {post['num_comments']}ê°œ
"""
        
        if post.get('selftext'):
            post_content += f"ë‚´ìš©: {post['selftext'][:300]}...\n"
        
        if post.get('top_comments'):
            post_content += "ì£¼ìš” ë°˜ì‘:\n"
            for j, comment in enumerate(post['top_comments'][:3], 1):
                comment_footnote = footnote_counter
                footnote_counter += 1
                post_content += f"â€¢ [{comment['score']}ì ] \"{comment['body'][:150]}...\" [{comment_footnote}]\n"
                
                all_footnotes.append({
                    'id': comment_footnote,
                    'type': 'comment',
                    'url': post['url'],
                    'text': f"ëŒ“ê¸€ from {post['title'][:30]}..."
                })
        
        news_content.append(post_content)
        all_footnotes.append({
            'id': footnote_id,
            'type': 'post',
            'url': post['url'],
            'title': f"{post['title']} - r/{post['subreddit']} ({time_str})"
        })
    
    # ë£¨ë¨¸ ì½˜í…ì¸  (ìƒìœ„ 25ê°œ)
    for i, post in enumerate(rumors_speculation[:25], 1):
        footnote_id = footnote_counter
        footnote_counter += 1
        
        post_time = datetime.fromtimestamp(post['created_utc'])
        time_diff = datetime.now() - post_time
        
        if time_diff.days > 0:
            time_str = f"{time_diff.days}ì¼ ì „"
        elif time_diff.seconds > 3600:
            time_str = f"{time_diff.seconds // 3600}ì‹œê°„ ì „"
        else:
            time_str = f"{time_diff.seconds // 60}ë¶„ ì „"
        
        post_content = f"""
ë£¨ë¨¸ {i}. [{post['score']}ì ] {post['title']} [{footnote_id}]
- ê²Œì‹œ ì‹œê°„: {post_time.strftime('%Y-%m-%d %H:%M')} ({time_str})
- ì¶œì²˜: r/{post['subreddit']}
- ëŒ“ê¸€: {post['num_comments']}ê°œ
"""
        
        if post.get('selftext'):
            post_content += f"ë‚´ìš©: {post['selftext'][:250]}...\n"
        
        if post.get('top_comments'):
            post_content += "ë°˜ì‘:\n"
            for j, comment in enumerate(post['top_comments'][:2], 1):
                comment_footnote = footnote_counter
                footnote_counter += 1
                post_content += f"â€¢ [{comment['score']}ì ] \"{comment['body'][:120]}...\" [{comment_footnote}]\n"
                
                all_footnotes.append({
                    'id': comment_footnote,
                    'type': 'comment',
                    'url': post['url'],
                    'text': f"ë£¨ë¨¸ ëŒ“ê¸€ from r/{post['subreddit']}"
                })
        
        rumors_content.append(post_content)
        all_footnotes.append({
            'id': footnote_id,
            'type': 'post',
            'url': post['url'],
            'title': f"{post['title']} - r/{post['subreddit']} ({time_str})"
        })
    
    # ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ ì „ëµ ì¤€ë¹„
    prompts = [
        # í”„ë¡¬í”„íŠ¸ 1: í˜„ì¬ ì‹œì  ê°•ì¡°
        {
            "system": f"""ë‹¹ì‹ ì€ Reddit ì†Œì…œë¯¸ë””ì–´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            ì£¼ì–´ì§„ Reddit ê²Œì‹œë¬¼ê³¼ ëŒ“ê¸€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ {topic}ì— ëŒ€í•œ ìµœì‹  ë™í–¥ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
            
            ì¤‘ìš”: ì´ ë°ì´í„°ëŠ” ì´ë¯¸ ìˆ˜ì§‘ëœ ê³¼ê±° ì •ë³´ì´ë¯€ë¡œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë¯¸ë˜ ì˜ˆì¸¡ì´ ì•„ë‹Œ í˜„ì¬ ìƒí™© ë¶„ì„ì…ë‹ˆë‹¤.
            
            ë³´ê³ ì„œ êµ¬ì¡°:
            1. í•µì‹¬ ìš”ì•½ (300ì ì´ìƒ)
            2. ì£¼ìš” ë‰´ìŠ¤ ë¶„ì„ (500ì ì´ìƒ) 
            3. ë£¨ë¨¸ ë° ì¶”ì¸¡ ì •ë³´ (400ì ì´ìƒ)
            4. ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ ë¶„ì„ (300ì ì´ìƒ)
            5. ì‹œì‚¬ì  (200ì ì´ìƒ)
            
            ê°ì£¼ [ìˆ«ì]ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.""",
            "user": f"""ë‹¤ìŒì€ Redditì—ì„œ ìˆ˜ì§‘í•œ {topic} ê´€ë ¨ ê²Œì‹œë¬¼ ë°ì´í„°ì…ë‹ˆë‹¤.

í™•ì¸ëœ ë‰´ìŠ¤ ({len(verified_news)}ê°œ):
{''.join(news_content[:10])}

ë£¨ë¨¸/ì¶”ì¸¡ ì •ë³´ ({len(rumors_speculation)}ê°œ):
{''.join(rumors_content[:10])}

ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì‹  ë™í–¥ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."""
        },
        
        # í”„ë¡¬í”„íŠ¸ 2: ë‹¨ìˆœí•œ ë¶„ì„ ìš”ì²­
        {
            "system": f"""ë‹¹ì‹ ì€ ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
            ì œê³µëœ Reddit ê²Œì‹œë¬¼ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ {topic}ì— ëŒ€í•œ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
            
            ìš”êµ¬ì‚¬í•­:
            - ìµœì†Œ 1500ì ì´ìƒ ì‘ì„±
            - ê°ì£¼ [ìˆ«ì] í¬í•¨
            - êµ¬ì²´ì ì¸ ë°ì´í„° ì¸ìš©
            - ëª…í™•í•œ ë¶„ì„ê³¼ í•´ì„""",
            "user": f"""Reddit ë°ì´í„° ë¶„ì„ ìš”ì²­:

ë‰´ìŠ¤ ë°ì´í„°:
{''.join(news_content[:8])}

ë£¨ë¨¸ ë°ì´í„°:  
{''.join(rumors_content[:8])}

ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì„œ ìƒì„¸í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."""
        },
        
        # í”„ë¡¬í”„íŠ¸ 3: êµ¬ì²´ì ì¸ ì§€ì‹œ
        {
            "system": f"""Reddit ê²Œì‹œë¬¼ ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:

1. ì œê³µëœ ê²Œì‹œë¬¼ê³¼ ëŒ“ê¸€ì„ ëª¨ë‘ ê²€í† 
2. {topic}ì˜ í˜„ì¬ ìƒí™© ì •ë¦¬
3. ì£¼ìš” ë…¼ì ê³¼ ë°˜ì‘ ë¶„ì„
4. ì¢…í•©ì ì¸ ë¶„ì„ ë³´ê³ ì„œ ì‘ì„±

ë°˜ë“œì‹œ 1000ì ì´ìƒ ì‘ì„±í•˜ê³ , ê°ì£¼ë¥¼ í¬í•¨í•˜ì„¸ìš”.""",
            "user": f"""ë¶„ì„í•  Reddit ë°ì´í„°:

ë‰´ìŠ¤: {len(verified_news)}ê°œ
{''.join(news_content[:6])}

ë£¨ë¨¸: {len(rumors_speculation)}ê°œ  
{''.join(rumors_content[:6])}

ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."""
        }
    ]
    
    # ì—¬ëŸ¬ ì‹œë„ë¡œ ë³´ê³ ì„œ ìƒì„±
    max_attempts = 3
    analysis = None
    
    for attempt in range(max_attempts):
        print(f"\nğŸ¤– GPT-4.1ë¡œ ë¶„ì„ ì‹œë„ {attempt + 1}/{max_attempts}...")
        
        try:
            prompt = prompts[attempt]
            
            response = client.chat.completions.create(
                model="gpt-4.1",
                messages=[
                    {"role": "system", "content": prompt["system"]},
                    {"role": "user", "content": prompt["user"]}
                ],
                temperature=0.6,
            )
            
            candidate_analysis = response.choices[0].message.content
            
            # ê²€ì¦ ìˆ˜í–‰
            is_valid, validation_message = validate_report_content(candidate_analysis)
            
            print(f"ğŸ“‹ ê²€ì¦ ê²°ê³¼: {validation_message}")
            
            if is_valid:
                analysis = candidate_analysis
                print(f"âœ… ì‹œë„ {attempt + 1}ì—ì„œ ì„±ê³µ!")
                break
            else:
                print(f"âŒ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {validation_message}")
                if attempt < max_attempts - 1:
                    print("ğŸ”„ ë‹¤ë¥¸ ì „ëµìœ¼ë¡œ ì¬ì‹œë„...")
                    time.sleep(2)  # ì ì‹œ ëŒ€ê¸°
                
        except Exception as e:
            print(f"âŒ ì‹œë„ {attempt + 1} ì˜¤ë¥˜: {e}")
            if attempt < max_attempts - 1:
                time.sleep(2)
    
    if not analysis:
        print("âŒ ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤!")
        return None, None
    
    # ê²€ì¦ í†µê³¼í•œ ë³´ê³ ì„œë¡œ íŒŒì¼ ìƒì„±
    footnotes_html = "<div class='footnotes'><h2>ğŸ“Œ ì°¸ê³  ë§í¬</h2><ol>"
    footnotes_md = "\n\n---\n\n## ğŸ“Œ ì°¸ê³  ë§í¬\n\n"
    
    for footnote in all_footnotes:
        footnotes_html += f"<li id='fn{footnote['id']}'><a href='{footnote['url']}' target='_blank'>{footnote['title'] if 'title' in footnote else footnote['text']}</a></li>"
        footnotes_md += f"{footnote['id']}. [{footnote['title'] if 'title' in footnote else footnote['text']}]({footnote['url']})\n"
    
    footnotes_html += "</ol></div>"
    
    # HTML ë³´ê³ ì„œ
    html_content = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{topic}: ê²€ì¦ëœ ìµœì‹  ë¶„ì„</title>
    <style>
        body {{
            font-family: 'Noto Sans KR', -apple-system, BlinkMacSystemFont, sans-serif;
            line-height: 1.8;
            color: #2c3e50;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f7fa;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 50px;
            border-radius: 20px;
            margin-bottom: 40px;
            box-shadow: 0 15px 35px rgba(0,0,0,0.1);
            text-align: center;
        }}
        .header h1 {{
            margin: 0;
            font-size: 2.5em;
            font-weight: 800;
        }}
        .verification-badge {{
            background: #27ae60;
            color: white;
            padding: 10px 20px;
            border-radius: 25px;
            margin-top: 15px;
            display: inline-block;
            font-weight: bold;
        }}
        .content {{
            background: white;
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 5px 20px rgba(0,0,0,0.08);
            margin-bottom: 30px;
        }}
        .content h1, .content h2, .content h3 {{
            color: #2c3e50;
            margin-top: 30px;
        }}
        .footnote-ref {{
            color: #667eea;
            text-decoration: none;
            font-weight: bold;
            font-size: 0.9em;
            vertical-align: super;
        }}
        .footnotes {{
            margin-top: 50px;
            padding-top: 30px;
            border-top: 3px solid #e0e0e0;
        }}
        .footnotes ol {{
            font-size: 0.9em;
            line-height: 1.8;
        }}
        .footnotes a {{
            color: #667eea;
            text-decoration: none;
        }}
        .stats-box {{
            background: #f8f9fa;
            padding: 25px;
            border-radius: 10px;
            margin: 25px 0;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 20px;
        }}
        .stats-item {{
            text-align: center;
        }}
        .stats-number {{
            font-size: 2em;
            font-weight: bold;
            color: #667eea;
        }}
    </style>
    <script>
        document.addEventListener('DOMContentLoaded', function() {{
            const content = document.querySelector('.content');
            content.innerHTML = content.innerHTML.replace(/\\[(\\d+)\\]/g, function(match, num) {{
                return '<a href="#fn' + num + '" class="footnote-ref">[' + num + ']</a>';
            }});
        }});
    </script>
</head>
<body>
    <div class="header">
        <h1>{dynamic_title}</h1>
        <div class="verification-badge">âœ… AI ê²€ì¦ í†µê³¼</div>
        <p>ğŸ“… {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')} ê¸°ì¤€</p>
        <p>ğŸ“Š Reddit {data['total_posts']}ê°œ ê²Œì‹œë¬¼ ë¶„ì„</p>
    </div>
    
    <div class="content">
        <div class="stats-box">
            <div class="stats-item">
                <div class="stats-number">{len(verified_news)}</div>
                <div>í™•ì¸ëœ ë‰´ìŠ¤</div>
            </div>
            <div class="stats-item">
                <div class="stats-number">{len(rumors_speculation)}</div>
                <div>ë£¨ë¨¸/ì¶”ì¸¡</div>
            </div>
            <div class="stats-item">
                <div class="stats-number">{len(all_footnotes)}</div>
                <div>ì°¸ì¡° ë§í¬</div>
            </div>
        </div>
        
        {analysis.replace(chr(10), '<br>').replace('# ', '<h1>').replace('## ', '<h2>').replace('### ', '<h3>')}
        
        {footnotes_html}
    </div>
</body>
</html>"""
    
    # Markdown ë³´ê³ ì„œ
    markdown_content = f"""# {dynamic_title}

## ğŸ“… {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')} ê¸°ì¤€

âœ… **AI ê²€ì¦ í†µê³¼**

### ğŸ“Š ë°ì´í„° ê°œìš”
- **ì „ì²´ ë¶„ì„ ê²Œì‹œë¬¼**: {data['total_posts']}ê°œ
- **í™•ì¸ëœ ë‰´ìŠ¤**: {len(verified_news)}ê°œ
- **ë£¨ë¨¸/ì¶”ì¸¡ì„± ì •ë³´**: {len(rumors_speculation)}ê°œ
- **ì°¸ì¡° ë§í¬**: {len(all_footnotes)}ê°œ

---

{analysis}

{footnotes_md}

---

*ì´ ë³´ê³ ì„œëŠ” AI ê²€ì¦ì„ í†µê³¼í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¶„ì„ì…ë‹ˆë‹¤.*
"""
    
    # íŒŒì¼ ì €ì¥
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # íŒŒì¼ëª…ì„ ë™ì  ì œëª©ì— ë§ê²Œ ìƒì„± (ê³µë°±ì„ ì–¸ë”ë°”ë¡œë§Œ ë³€ê²½)
    safe_title = dynamic_title.replace(' ', '_').lower()[:50]
    ai_analysis_dir = os.path.join(project_root, "reports", "ai_analysis")
    os.makedirs(ai_analysis_dir, exist_ok=True)
    
    html_path = os.path.join(ai_analysis_dir, f"verified_{safe_title}_{timestamp}.html")
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    md_path = os.path.join(ai_analysis_dir, f"verified_{safe_title}_{timestamp}.md")
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(markdown_content)
    
    print(f"\nâœ… ê²€ì¦ëœ ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“„ HTML ë³´ê³ ì„œ: {os.path.abspath(html_path)}")
    print(f"ğŸ“ Markdown ë³´ê³ ì„œ: {os.path.abspath(md_path)}")
    print(f"ğŸ“Š í†µê³„:")
    print(f"   - í™•ì¸ëœ ë‰´ìŠ¤: {len(verified_news)}ê°œ")
    print(f"   - ë£¨ë¨¸/ì¶”ì¸¡: {len(rumors_speculation)}ê°œ")
    print(f"   - ì´ ê°ì£¼: {len(all_footnotes)}ê°œ")
    
    return html_path, md_path

if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ìë¡œ ì£¼ì œ ë°›ê¸°
    if len(sys.argv) > 1:
        search_topic = sys.argv[1]
        create_verified_detailed_analysis(search_topic)
    else:
        create_verified_detailed_analysis()